{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dff4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38162a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "from src.datasets import ARDataset\n",
    "from src.utils import ObjectView, get_cls_by_name, get_optimizer, get_fn_param_names\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import contextlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ObjectView(dict(\n",
    "    seed = 42,\n",
    "    save_path = \"/home/user36/metamem/runs\",\n",
    "\n",
    "    # LM model args\n",
    "    arch = \"gpt_neox\",\n",
    "    hidden_size = 128,\n",
    "    num_hidden_layers = 4,\n",
    "    num_attention_heads = 4,\n",
    "\n",
    "    # AR dataset args\n",
    "    num_symbols = 16,\n",
    "    key_size = 2,\n",
    "    value_size = 1,\n",
    "    num_pairs = 16,\n",
    "    ar_mode = \"remember\",\n",
    "\n",
    "    pretrain_size = 100000,\n",
    "    train_size = 100000,\n",
    "    valid_size = 1000,\n",
    "    test_size = 10000,\n",
    "    data_n_workers = 4,\n",
    "\n",
    "    # meta memory args\n",
    "    num_mem_tokens = 4,\n",
    "    use_lora = False,\n",
    "    max_inner_iter = 1000,\n",
    "    inner_target_loss = 0.0,\n",
    "\n",
    "    # train args\n",
    "    iters = 10000,\n",
    "    log_interval = 100,\n",
    "    valid_interval = 500,\n",
    "    batch_size = 128,\n",
    "    gradient_accumulation_steps = 1,\n",
    "\n",
    "    # optimizer args\n",
    "    inner_optimizer = \"SGD\",\n",
    "    inner_lr = 1e-3,\n",
    "    inner_momentum = 0.9,\n",
    "    inner_weight_decay = 1e-2,\n",
    "    nesterov = True,\n",
    "\n",
    "    optimizer = \"AdamW\",\n",
    "    lr = 3e-4,\n",
    "    weight_decay = 1e-2,\n",
    "    lr_scheduler = \"linear\",\n",
    "    # num_warmup_steps = 1000,\n",
    "\n",
    "    best_metric_value = 1.0,\n",
    "    optimize_mode = 'max',\n",
    "))\n",
    "\n",
    "args['num_warmup_steps'] = args['iters'] // 10\n",
    "args_cp = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc141b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token, impl_token, gen_token, eos_token = 100, 101, 102, 103\n",
    "\n",
    "def collate_fn(batch, valid=False):\n",
    "    keys = [b['keys'] for b in batch]\n",
    "    values = [b['values'] for b in batch]\n",
    "    tgt_inds = [b['target_key_idx'].item() for b in batch]\n",
    "    n = len(keys[0])\n",
    "\n",
    "    bs = len(keys)\n",
    "    sep_tokens = torch.ones(bs, 1) * sep_token\n",
    "    impl_tokens = torch.ones(bs, 1) * impl_token\n",
    "    eos_tokens = torch.ones(bs, 1) * eos_token\n",
    "    gen_tokens = torch.ones(bs, 1) * gen_token\n",
    "    sample = []\n",
    "\n",
    "    for i in range(n):\n",
    "        sample.append(torch.stack([k[i] for k in keys]))\n",
    "        sample.append(impl_tokens)\n",
    "        sample.append(torch.stack([v[i] for v in values]))\n",
    "        sample.append(sep_tokens)\n",
    "\n",
    "    target_keys = torch.stack([k[i] for i, k in zip(tgt_inds, keys)])\n",
    "    target_values = torch.stack([k[i] for i, k in zip(tgt_inds, values)])\n",
    "\n",
    "    sample.append(target_keys)\n",
    "    sample.append(gen_tokens)\n",
    "\n",
    "    input_ids_generate = torch.cat(sample, dim=1)\n",
    "\n",
    "    sample.append(target_values)\n",
    "    sample.append(eos_tokens)\n",
    "    input_ids = torch.cat(sample, dim=1)\n",
    "\n",
    "    labels_mask = torch.zeros_like(input_ids).bool()\n",
    "    labels_mask[:, -args.value_size - 2:] = True\n",
    "\n",
    "    collated = {\n",
    "        'input_ids': input_ids.long(), \n",
    "        'input_ids_generate': input_ids_generate.long(), \n",
    "        'attention_mask': torch.ones_like(input_ids).bool(),\n",
    "        'attention_mask_generate': torch.ones_like(input_ids_generate).bool(),\n",
    "        'labels': input_ids.long(), \n",
    "        'labels_mask': labels_mask, \n",
    "        'target_values': target_values,\n",
    "    }\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0591a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b15037c6da4addafef69967c935162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a6bd2450074e05be5d878f92bc0eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "\n",
    "pretrain_dataset = ARDataset(args.key_size, args.value_size, num_pairs=args.num_pairs, num_samples=args.pretrain_size)\n",
    "# train_dataset = ARDataset(args.key_size, args.value_size, sample_len=args.num_pairs, num_samples=args.train_size)\n",
    "valid_dataset = ARDataset(args.key_size, args.value_size, num_pairs=args.num_pairs, num_samples=args.valid_size)\n",
    "# test_dataset = ARDataset(args.key_size, args.value_size, sample_len=args.num_pairs, num_samples=args.test_size)\n",
    "\n",
    "train_rnd_generator = torch.Generator()\n",
    "train_rnd_generator.manual_seed(args.seed)\n",
    "per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "\n",
    "pretrain_dataloader = DataLoader(pretrain_dataset, batch_size=per_worker_batch_size, generator=train_rnd_generator,\n",
    "                                 collate_fn=collate_fn, **kwargs)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=per_worker_batch_size,  generator=train_rnd_generator,\n",
    "#                         collate_fn=collate_fn, **kwargs)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=per_worker_batch_size,\n",
    "                        collate_fn=collate_fn, **kwargs)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=per_worker_batch_size,\n",
    "#                         collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164eff33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving config gpt_neox_tiny_4l4hd128\n"
     ]
    }
   ],
   "source": [
    "%run ../src/configs/base_models/create_config.py --arch gpt_neox --hidden_size 128 --num_hidden_layers 4 --num_attention_heads 4\n",
    "\n",
    "# model_config = json.load(f\"{args.arch}_tiny_{args.num_hidden_layers}l{args.num_attention_heads}hd{args.hidden_size}\")\n",
    "cfg_path = f\"/home/user36/metamem/src/configs/base_models/exp/{args.arch}_tiny_{args.num_hidden_layers}l{args.num_attention_heads}hd{args.hidden_size}.json\"\n",
    "model_cfg = AutoConfig.from_pretrained(cfg_path)\n",
    "\n",
    "model_cls = get_cls_by_name(f\"transformers:{model_cfg.architectures[0]}\")\n",
    "model = model_cls(config=model_cfg)\n",
    "args = args_cp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer_cls = get_optimizer(args.optimizer)\n",
    "optimizer = optimizer_cls(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "lr_scheduler = get_scheduler(args.lr_scheduler, optimizer, args.num_warmup_steps, args.iters * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f5d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels_mask, target_values):\n",
    "    preds = torch.argmax(logits.detach(), dim=-1)\n",
    "    pred_labels = [p[m] for p, m in zip(preds, labels_mask)]\n",
    "\n",
    "    for i, l in enumerate(pred_labels):\n",
    "        if eos_token in l:\n",
    "            pl = pred_labels[i].tolist()\n",
    "            eos_ind = pl.index(eos_token)\n",
    "            pred_labels[i] = pl[:eos_ind]\n",
    "\n",
    "    correct = np.sum([text == pred for text, pred in zip (target_values.tolist(), pred_labels)])\n",
    "    total = target_values.shape[0]\n",
    "    acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "\n",
    "    return acc, correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f29761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # move to device\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(device)\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                labels=batch['labels'],\n",
    "                labels_mask=batch['labels_mask'],\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "\n",
    "            shift_labels = batch['labels'][..., 1:].contiguous()\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            flat_labels = shift_labels.view(-1)\n",
    "            flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            shift_mask = batch['labels_mask'][..., :-1].contiguous()\n",
    "            flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "            flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "        \n",
    "            loss = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "            acc, correct, total = compute_accuracy(logits, batch['labels_mask'], batch['target_values'])\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += correct\n",
    "            val_total += total\n",
    "        \n",
    "        # idx = torch.randint(total, (5,))\n",
    "        # print(\"Showing valid examples\")\n",
    "        # for i in idx:\n",
    "        #     print(f\"y = {batch['target_values'][i]}\")\n",
    "        #     print(f\"p = {pred_labels[i]}\")\n",
    "        # print(\"-\" * 30)\n",
    "\n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    avg_acc = 100.0 * val_correct / val_total\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac774161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    args\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs exactly args.iters iterations over train_dataloader,\n",
    "    validates every args.validate_interval steps (and once at the end),\n",
    "    and logs train loss & acc every args.log_interval steps.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_iter = iter(train_dataloader)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    pbar = tqdm(total=args.iters, desc='Train')\n",
    "    for step in range(args.iters):\n",
    "        pbar.update(1)\n",
    "        # fetch next batch (restarting the iterator as needed)\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:\n",
    "            train_iter = iter(train_dataloader)\n",
    "            batch = next(train_iter)\n",
    "\n",
    "        # move to device\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "        # forward + backward + step\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels'],\n",
    "            labels_mask=batch['labels_mask'],\n",
    "        )\n",
    "        # loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        shift_labels = batch['labels'][..., 1:].contiguous()\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        flat_labels = shift_labels.view(-1)\n",
    "        flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        shift_mask = batch['labels_mask'][..., :-1].contiguous()\n",
    "        flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "        flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "    \n",
    "        loss = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # accumulate for logging\n",
    "        acc, correct, total = compute_accuracy(logits, batch['labels_mask'], batch['target_values'])\n",
    "        running_loss += loss.item()\n",
    "        running_correct += correct\n",
    "        running_total += total\n",
    "\n",
    "        # train-side logging\n",
    "        if step % args.log_interval == 0 or step == args.iters:\n",
    "            elapsed = (time.time() - start_time) / step if step > 0 else 0\n",
    "            avg_loss = running_loss / args.log_interval\n",
    "            avg_acc = 100.0 * running_correct / running_total if running_total > 0 else 0.0\n",
    "            print(f\"[Train] Step {step:5d}/{args.iters:5d} • \"\n",
    "                  f\"Loss: {avg_loss:.4f} • Acc: {avg_acc:5.2f}% • \"\n",
    "                  f\"{elapsed:.3f}s/step\")\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "\n",
    "        # periodic validation\n",
    "        if step % args.valid_interval == 0:\n",
    "            val_loss, val_acc = validate(model, valid_dataloader, device)\n",
    "            print(f\"⏸ [Valid] after {step} steps → \"\n",
    "                  f\"Val Loss: {val_loss:.4f} • Val Acc: {val_acc:5.2f}%\")\n",
    "            # save best\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), f\"{args.save_path}/model.pth\")\n",
    "                print(f\"  ✔ New best model saved at step {step} → {args.save_path}\")\n",
    "\n",
    "    # final validation at end if not aligned to interval\n",
    "    if args.iters % args.valid_interval != 0:\n",
    "        val_loss, val_acc = validate(model, valid_dataloader, device)\n",
    "        print(f\"⏸ [Valid] final → Val Loss: {val_loss:.4f} • Val Acc: {val_acc:5.2f}%\")\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save(model.state_dict(), f\"{args.save_path}/model.pth\")\n",
    "            print(f\"  ✔ New best model saved at final step → {args.save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb639b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step     0/10000 • Loss: 0.0485 • Acc:  0.00% • 0.000s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 0 steps → Val Loss: 4.8345 • Val Acc:  0.00%\n",
      "  ✔ New best model saved at step 0 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   100/10000 • Loss: 3.9661 • Acc:  0.09% • 0.321s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   200/10000 • Loss: 2.8476 • Acc:  3.65% • 0.298s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   300/10000 • Loss: 2.1671 • Acc:  6.15% • 0.242s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   400/10000 • Loss: 1.7210 • Acc:  6.92% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   500/10000 • Loss: 1.5324 • Acc:  7.27% • 0.215s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 500 steps → Val Loss: 1.4871 • Val Acc:  0.05%\n",
      "  ✔ New best model saved at step 500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   600/10000 • Loss: 1.4595 • Acc:  7.67% • 0.229s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   700/10000 • Loss: 1.4204 • Acc:  9.36% • 0.228s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   800/10000 • Loss: 1.3946 • Acc: 10.85% • 0.219s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step   900/10000 • Loss: 1.3758 • Acc: 11.25% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1000/10000 • Loss: 1.3593 • Acc: 11.96% • 0.217s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 1000 steps → Val Loss: 1.3252 • Val Acc:  0.16%\n",
      "  ✔ New best model saved at step 1000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1100/10000 • Loss: 1.3197 • Acc: 14.61% • 0.225s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1200/10000 • Loss: 1.2823 • Acc: 15.72% • 0.217s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1300/10000 • Loss: 1.2596 • Acc: 17.25% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1400/10000 • Loss: 1.2530 • Acc: 16.91% • 0.203s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1500/10000 • Loss: 1.2325 • Acc: 17.67% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 1500 steps → Val Loss: 1.2141 • Val Acc:  0.17%\n",
      "  ✔ New best model saved at step 1500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1600/10000 • Loss: 1.2310 • Acc: 17.56% • 0.214s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1700/10000 • Loss: 1.2299 • Acc: 17.22% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1800/10000 • Loss: 1.2236 • Acc: 17.49% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  1900/10000 • Loss: 1.2109 • Acc: 18.02% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2000/10000 • Loss: 1.2011 • Acc: 18.27% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 2000 steps → Val Loss: 1.1851 • Val Acc:  0.17%\n",
      "  ✔ New best model saved at step 2000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2100/10000 • Loss: 1.1966 • Acc: 18.90% • 0.212s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2200/10000 • Loss: 1.1884 • Acc: 18.58% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2300/10000 • Loss: 1.1799 • Acc: 18.56% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2400/10000 • Loss: 1.1790 • Acc: 18.82% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2500/10000 • Loss: 1.1793 • Acc: 18.05% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 2500 steps → Val Loss: 1.1497 • Val Acc:  0.20%\n",
      "  ✔ New best model saved at step 2500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2600/10000 • Loss: 1.1758 • Acc: 18.10% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2700/10000 • Loss: 1.1702 • Acc: 18.29% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2800/10000 • Loss: 1.1597 • Acc: 19.05% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  2900/10000 • Loss: 1.1633 • Acc: 19.03% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3000/10000 • Loss: 1.1572 • Acc: 18.85% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 3000 steps → Val Loss: 1.1486 • Val Acc:  0.18%\n",
      "  ✔ New best model saved at step 3000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3100/10000 • Loss: 1.1499 • Acc: 19.26% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3200/10000 • Loss: 1.1579 • Acc: 18.20% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3300/10000 • Loss: 1.1543 • Acc: 18.40% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3400/10000 • Loss: 1.1551 • Acc: 17.88% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3500/10000 • Loss: 1.1481 • Acc: 18.80% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 3500 steps → Val Loss: 1.1328 • Val Acc:  0.18%\n",
      "  ✔ New best model saved at step 3500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3600/10000 • Loss: 1.1431 • Acc: 19.08% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3700/10000 • Loss: 1.1475 • Acc: 19.54% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3800/10000 • Loss: 1.1417 • Acc: 18.92% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  3900/10000 • Loss: 1.1412 • Acc: 19.02% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4000/10000 • Loss: 1.1437 • Acc: 18.50% • 0.210s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 4000 steps → Val Loss: 1.1291 • Val Acc:  0.18%\n",
      "  ✔ New best model saved at step 4000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4100/10000 • Loss: 1.1473 • Acc: 18.18% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4200/10000 • Loss: 1.1420 • Acc: 18.74% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4300/10000 • Loss: 1.1385 • Acc: 18.97% • 0.213s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4400/10000 • Loss: 1.1357 • Acc: 19.30% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4500/10000 • Loss: 1.1383 • Acc: 19.30% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 4500 steps → Val Loss: 1.1304 • Val Acc:  0.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4600/10000 • Loss: 1.1338 • Acc: 19.38% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4700/10000 • Loss: 1.1341 • Acc: 19.24% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4800/10000 • Loss: 1.1402 • Acc: 18.64% • 0.211s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  4900/10000 • Loss: 1.1383 • Acc: 18.30% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5000/10000 • Loss: 1.1351 • Acc: 18.97% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 5000 steps → Val Loss: 1.1225 • Val Acc:  0.19%\n",
      "  ✔ New best model saved at step 5000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5100/10000 • Loss: 1.1328 • Acc: 19.09% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5200/10000 • Loss: 1.1298 • Acc: 19.19% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5300/10000 • Loss: 1.1351 • Acc: 19.60% • 0.209s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5400/10000 • Loss: 1.1247 • Acc: 19.55% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5500/10000 • Loss: 1.1314 • Acc: 19.25% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 5500 steps → Val Loss: 1.1234 • Val Acc:  0.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5600/10000 • Loss: 1.1369 • Acc: 18.80% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5700/10000 • Loss: 1.1327 • Acc: 18.66% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5800/10000 • Loss: 1.1307 • Acc: 18.79% • 0.208s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  5900/10000 • Loss: 1.1251 • Acc: 19.63% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6000/10000 • Loss: 1.1277 • Acc: 19.12% • 0.205s/step\n",
      "⏸ [Valid] after 6000 steps → Val Loss: 1.1270 • Val Acc:  0.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6100/10000 • Loss: 1.1276 • Acc: 19.56% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6200/10000 • Loss: 1.1220 • Acc: 20.00% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6300/10000 • Loss: 1.1289 • Acc: 19.25% • 0.207s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6400/10000 • Loss: 1.1309 • Acc: 19.05% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6500/10000 • Loss: 1.1281 • Acc: 18.98% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 6500 steps → Val Loss: 1.1233 • Val Acc:  0.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6600/10000 • Loss: 1.1262 • Acc: 18.97% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6700/10000 • Loss: 1.1177 • Acc: 20.34% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6800/10000 • Loss: 1.0999 • Acc: 21.32% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  6900/10000 • Loss: 1.0226 • Acc: 24.80% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7000/10000 • Loss: 0.8661 • Acc: 33.30% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 7000 steps → Val Loss: 0.7867 • Val Acc:  0.36%\n",
      "  ✔ New best model saved at step 7000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7100/10000 • Loss: 0.6059 • Acc: 49.93% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7200/10000 • Loss: 0.2856 • Acc: 76.12% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7300/10000 • Loss: 0.1590 • Acc: 87.12% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7400/10000 • Loss: 0.0960 • Acc: 92.49% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7500/10000 • Loss: 0.0512 • Acc: 96.27% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 7500 steps → Val Loss: 0.0314 • Val Acc:  0.98%\n",
      "  ✔ New best model saved at step 7500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7600/10000 • Loss: 0.0386 • Acc: 97.44% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7700/10000 • Loss: 0.0310 • Acc: 97.99% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7800/10000 • Loss: 0.0285 • Acc: 97.91% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  7900/10000 • Loss: 0.0272 • Acc: 97.94% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8000/10000 • Loss: 0.0249 • Acc: 98.17% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 8000 steps → Val Loss: 0.0246 • Val Acc:  0.98%\n",
      "  ✔ New best model saved at step 8000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8100/10000 • Loss: 0.0312 • Acc: 97.74% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8200/10000 • Loss: 0.0260 • Acc: 97.85% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8300/10000 • Loss: 0.0195 • Acc: 98.69% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8400/10000 • Loss: 0.0148 • Acc: 98.89% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8500/10000 • Loss: 0.0123 • Acc: 99.25% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 8500 steps → Val Loss: 0.0233 • Val Acc:  0.98%\n",
      "  ✔ New best model saved at step 8500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8600/10000 • Loss: 0.0109 • Acc: 99.38% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8700/10000 • Loss: 0.0091 • Acc: 99.54% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8800/10000 • Loss: 0.0098 • Acc: 99.34% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  8900/10000 • Loss: 0.0152 • Acc: 98.88% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9000/10000 • Loss: 0.0094 • Acc: 99.41% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 9000 steps → Val Loss: 0.0100 • Val Acc:  0.99%\n",
      "  ✔ New best model saved at step 9000 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9100/10000 • Loss: 0.0128 • Acc: 99.10% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9200/10000 • Loss: 0.0091 • Acc: 99.43% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9300/10000 • Loss: 0.0090 • Acc: 99.42% • 0.204s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9400/10000 • Loss: 0.0083 • Acc: 99.42% • 0.205s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step  9500/10000 • Loss: 0.0081 • Acc: 99.49% • 0.206s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸ [Valid] after 9500 steps → Val Loss: 0.0068 • Val Acc:  1.00%\n",
      "  ✔ New best model saved at step 9500 → /home/user36/metamem/runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(model, train_dataloader, valid_dataloader, optimizer, scheduler, device, args)\u001b[39m\n\u001b[32m     66\u001b[39m scheduler.step()\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# accumulate for logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m acc, correct, total = \u001b[43mcompute_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_values\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m running_loss += loss.item()\n\u001b[32m     71\u001b[39m running_correct += correct\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcompute_accuracy\u001b[39m\u001b[34m(logits, labels_mask, target_values)\u001b[39m\n\u001b[32m      3\u001b[39m pred_labels = [p[m] \u001b[38;5;28;01mfor\u001b[39;00m p, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, labels_mask)]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pred_labels):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43meos_token\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m:\n\u001b[32m      7\u001b[39m         pl = pred_labels[i].tolist()\n\u001b[32m      8\u001b[39m         eos_ind = pl.index(eos_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/_tensor.py:1254\u001b[39m, in \u001b[36mTensor.__contains__\u001b[39m\u001b[34m(self, element)\u001b[39m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.\u001b[34m__contains__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, element)\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1251\u001b[39m     element, (torch.Tensor, Number, torch.SymInt, torch.SymFloat, torch.SymBool)\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1257\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1258\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fit(model, pretrain_dataloader, valid_dataloader, optimizer, lr_scheduler, device, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4eadd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd93b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  96%|█████████▌| 9575/10000 [1:32:47<04:07,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d716253c3add415bad9af9999cafcad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/453 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a20dff6cd84413bbcc8a9d43da95f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/43.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cf6b9ccc2f42d4b85fbde3abd0ef22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid-00000-of-00001.parquet:   0%|          | 0.00/218k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b9b944b03451e93fadb5e0aed996e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ad16d7ac148249e15eba7e2b1833b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"yurakuratov/N1-K4V4-S1_16-32_1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc02e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'mVne8R!TGcU:ghK9!DnW|', 'query': '?!TGcU:', 'target': 'ghK9!|'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbb54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54661f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc9c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(format=logger_fmt, level=logging.INFO)\n",
    "logger = logging.getLogger('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_for_metrics_fn(batch, output):\n",
    "    # select data from batch and model output that would be used to compute metrics\n",
    "    data = {}\n",
    "    if 'generation_outputs' in output:\n",
    "        data['labels'] = batch['labels']\n",
    "        data['labels_mask'] = batch['labels_mask']\n",
    "        data['generation_outputs'] = output['generation_outputs']\n",
    "\n",
    "    for key in batch.keys():\n",
    "        if 'loss' in key: \n",
    "            data[key] = batch[key]\n",
    "\n",
    "    return data\n",
    "\n",
    "def metrics_fn(data):\n",
    "    metrics = {}\n",
    "    y, p = None, None\n",
    "    if 'generation_outputs' in data:\n",
    "        y = data['labels']\n",
    "        p = data['generation_outputs']\n",
    "\n",
    "        metrics['exact_match'] = np.mean([(len(p_) >= args.value_size + 1) and torch.all(torch.tensor(y_)[-args.value_size - 1:] == torch.tensor(p_[-args.value_size - 1:])) \\\n",
    "                                            for p_, y_ in zip (p, y)])\n",
    "        if args.show_valid_examples > 0:\n",
    "            for i in range(min(args.show_valid_examples, len(y))):\n",
    "                logger.info(f\"labels: {data['labels'][i]}\")\n",
    "                logger.info(f\"gen: {data['generation_outputs'][i]}\")\n",
    "                logger.info(f'y: {y[i][-args.value_size - 1:]}')\n",
    "                logger.info(f'p: {p[i][-args.value_size - 1:]}')\n",
    "\n",
    "                logger.info('-' * 50)\n",
    "    return metrics\n",
    "\n",
    "batch_metrics_fn = lambda _, y: {key: y[key] for key in y.keys() if (('loss' in key) or ('!log' in key))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b568fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'save_path': '/home/user36/metamem/runs',\n",
       " 'arch': 'gpt_neox',\n",
       " 'hidden_size': 128,\n",
       " 'num_hidden_layers': 4,\n",
       " 'num_attention_heads': 4,\n",
       " 'num_symbols': 16,\n",
       " 'key_size': 2,\n",
       " 'value_size': 1,\n",
       " 'num_pairs': 16,\n",
       " 'ar_mode': 'remember',\n",
       " 'pretrain_size': 100000,\n",
       " 'train_size': 100000,\n",
       " 'valid_size': 1000,\n",
       " 'test_size': 10000,\n",
       " 'data_n_workers': 4,\n",
       " 'num_mem_tokens': 4,\n",
       " 'use_lora': False,\n",
       " 'max_inner_iter': 1000,\n",
       " 'inner_target_loss': 0.0,\n",
       " 'iters': 10000,\n",
       " 'log_interval': 5,\n",
       " 'valid_interval': 25,\n",
       " 'batch_size': 128,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'inner_optimizer': 'SGD',\n",
       " 'inner_lr': 0.001,\n",
       " 'inner_momentum': 0.9,\n",
       " 'inner_weight_decay': 0.01,\n",
       " 'nesterov': True,\n",
       " 'optimizer': 'AdamW',\n",
       " 'lr': 0.0003,\n",
       " 'weight_decay': 0.01,\n",
       " 'lr_scheduler': 'linear',\n",
       " 'num_warmup_steps': 1000,\n",
       " '_ipython_canary_method_should_not_exist_': {}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forward_args = set(get_fn_param_names(model.forward))\n",
    "forward_kwargs = {}\n",
    "generate_kwargs={'max_new_tokens': int(args.value_size * 2), 'pad_token_id': 103}\n",
    "\n",
    "                      \n",
    "\n",
    "def step(model, batch, optimizer, args, is_train_mode=True):\n",
    "    if is_train_mode:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    batch_sizes = []\n",
    "    for k in batch:\n",
    "        # filter keys in batch to pass to model only supported arguments\n",
    "        if k in batch.keys():\n",
    "            batch[k] = batch[k].to(device)\n",
    "            batch_sizes += [batch[k].size(dim=0)]\n",
    "    if not np.all(np.array(batch_sizes) == batch_sizes[0]):\n",
    "        raise RuntimeError(f'not all elements in a batch have equal dim 0 size: {batch_sizes}')\n",
    "    batch_size = batch_sizes[0]\n",
    "\n",
    "    batch_metrics = defaultdict(lambda: 0.0)\n",
    "    batch_metrics_data = defaultdict(lambda: [])\n",
    "    with torch.set_grad_enabled(is_train_mode):\n",
    "        for j in range(0, batch_size, args.batch_size):\n",
    "            is_last_batch = (j == (batch_size // args.batch_size - 1) * args.batch_size)\n",
    "            # grad_sync_context = contextlib.nullcontext if is_last_batch else self.accelerator.no_sync\n",
    "            grad_sync_context = contextlib.nullcontext\n",
    "            with grad_sync_context(model):\n",
    "                subbatch = {k: batch[k][j: j + args.batch_size].to('cuda') for k in batch}\n",
    "                # filter items from batch that are not used by model forward\n",
    "                outputs = model(**{k: subbatch[k] for k in subbatch if k in model_forward_args},\n",
    "                                        **forward_kwargs)\n",
    "                loss = outputs['loss']\n",
    "                # divide loss on gradient_accumulation_steps to get average loss for sub-batches\n",
    "                # no need, accelerate does it internally (need to pass gradient_accumulation_steps to accelerator)\n",
    "                # loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                if not is_train_mode and args.use_generate_on_valid:\n",
    "                    generate_kwargs = deepcopy(generate_kwargs)\n",
    "                    if 'max_length' not in generate_kwargs and 'labels' in subbatch:\n",
    "                        # if max_length is not set and labels are in subbatch, generate to the length of labels+1\n",
    "                        # +1 as special tokens could be generated by the model\n",
    "                        generate_kwargs['max_length'] = subbatch['labels'].shape[-1] + 1\n",
    "                    if 'attention_mask' in subbatch:\n",
    "                        generate_kwargs['attention_mask'] = subbatch['attention_mask']\n",
    "                    if 'global_attention_mask' in subbatch:\n",
    "                        generate_kwargs['global_attention_mask'] = subbatch['global_attention_mask']\n",
    "                    generation_outputs = model.generate(subbatch['input_ids'], **generate_kwargs)\n",
    "                    outputs['generation_outputs'] = generation_outputs\n",
    "\n",
    "                metrics = batch_metrics_fn(subbatch, outputs)\n",
    "\n",
    "                for k in metrics:\n",
    "                    metrics[k] = metrics[k] / args.gradient_accumulation_steps\n",
    "                    if isinstance(metrics[k], torch.Tensor):\n",
    "                        metrics[k] = metrics[k].detach().item()\n",
    "                    batch_metrics[k] += metrics[k]\n",
    "\n",
    "                if keep_for_metrics_fn and metrics_fn:\n",
    "                    for k, v in keep_for_metrics_fn(subbatch, outputs).items():\n",
    "                        batch_metrics_data[k] += [v.detach().cpu() if isinstance(v, torch.Tensor) else v]\n",
    "\n",
    "                if is_train_mode:\n",
    "                    loss.backward()\n",
    "\n",
    "        if is_train_mode:\n",
    "            # log gradients norm, clip gradients and perform opt.step(), lr_scheduler.step()\n",
    "            # if self.clip_grad:\n",
    "            #     global_grad_norm = self._clip_gradients()\n",
    "            # else:\n",
    "            #     global_grad_norm = self._get_gradients_global_norm()\n",
    "            # track clipped grad norms\n",
    "            # global_grad_norms += [global_grad_norm]\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "        return batch_metrics, batch_metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_batch_generator(train_dataloader, n_iter, args):\n",
    "    for batch in train_dataloader:\n",
    "        if n_iter > args.iters:\n",
    "            return\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics = defaultdict(lambda: defaultdict(list))\n",
    "metrics_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "\n",
    "def collect_metrics(split: str) -> dict:\n",
    "    if split is None:\n",
    "        batch_metrics = defaultdict(lambda: defaultdict(list))\n",
    "    else:\n",
    "        batch_metrics[split] = defaultdict(list)\n",
    "    if split is None:\n",
    "        metrics_data = defaultdict(lambda: defaultdict(list))\n",
    "    else:\n",
    "        metrics_data[split] = defaultdict(list)\n",
    "\n",
    "\n",
    "    metrics = {}\n",
    "    metrics_keys = set(list(batch_metrics[split].keys()))\n",
    "    \n",
    "    # if metrics_keys != batch_metrics[split].keys():\n",
    "    #     missing_metrics_keys = metrics_keys - batch_metrics[split].keys()\n",
    "\n",
    "    metrics_keys = sorted(metrics_keys)\n",
    "    for k in metrics_keys:\n",
    "        metrics[k] = batch_metrics[split][k]\n",
    "        metrics[k] = np.mean(metrics[k])\n",
    "    # compute metrics from metrics data\n",
    "    if keep_for_metrics_fn and metrics_fn:\n",
    "        metrics_data = {}\n",
    "        data_keys = set(list(metrics_data[split].keys()))\n",
    "\n",
    "        # if data_keys != metrics_data[split].keys():\n",
    "            # missing_data_keys = data_keys - metrics_data[split].keys()\n",
    "    \n",
    "        data_keys = sorted(data_keys)\n",
    "        for k in data_keys:\n",
    "            metrics_data[k] = metrics_data[split][k]\n",
    "            m_shape = getattr(metrics_data[k][0], 'shape', None)\n",
    "            if m_shape is None:\n",
    "                # data is not a tensor, collect it into python list\n",
    "                metrics_data[k] = list(chain.from_iterable(metrics_data[k]))\n",
    "            elif len(m_shape) == 0:\n",
    "                # if scalars\n",
    "                metrics_data[k] = torch.stack(metrics_data[k])\n",
    "            elif all(m_shape[1:] == t.shape[1:] for t in metrics_data[k]):\n",
    "                # concat tensors if all shapes are equal except the first\n",
    "                metrics_data[k] = torch.cat(metrics_data[k])\n",
    "            else:\n",
    "                # can't concat tensors with diff last shapes, so collecting them into python list\n",
    "                metrics_data[k] = list(chain.from_iterable([t.tolist() for t in metrics_data[k]]))\n",
    "        m = metrics_fn(metrics_data)\n",
    "        if len(metrics.keys() & m.keys()) != 0:\n",
    "            logger.warning(f'metrics ({m.keys()}) and batch-lvl metrics ({metrics.keys()}) have common names. '\n",
    "                            f'Batch-lvl metric value would be overwritten.')\n",
    "        metrics.update(m)\n",
    "\n",
    "    metrics[split] = metrics\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "def _add_batch_metrics(batch_metrics_add: Dict[str, Union[float, torch.Tensor]], split: str):\n",
    "    for k in batch_metrics:\n",
    "        batch_metrics[split][k] += [batch_metrics_add[k]]\n",
    "\n",
    "def _add_metrics_data(metrics_data_add: Dict[str, torch.Tensor], split: str):\n",
    "    for k in metrics_data:\n",
    "        metrics_data[split][k] += metrics_data_add[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd793cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(dataloader, split='valid') -> Dict[str, float]:\n",
    "    logger.info('start validation')\n",
    "    \n",
    "    if split is None:\n",
    "        batch_metrics = defaultdict(lambda: defaultdict(list))\n",
    "    else:\n",
    "        batch_metrics[split] = defaultdict(list)\n",
    "    if split is None:\n",
    "        metrics_data = defaultdict(lambda: defaultdict(list))\n",
    "    else:\n",
    "        metrics_data[split] = defaultdict(list)\n",
    "\n",
    "    n_valid_batches = None\n",
    "    try:\n",
    "        n_valid_batches = len(dataloader)\n",
    "    except TypeError:\n",
    "        # in case if dataset has no len() method (IterableDataset?)\n",
    "        n_valid_batches = None\n",
    "\n",
    "    pbar = tqdm(total=n_valid_batches, desc='Validation')\n",
    "    for batch in dataloader:\n",
    "        batch_metrics, batch_metrics_data = step(batch, is_train_mode=False)\n",
    "        _add_batch_metrics(batch_metrics, split=split)\n",
    "        if keep_for_metrics_fn and metrics_fn:\n",
    "            _add_metrics_data(batch_metrics_data, split=split)\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "\n",
    "    # metrics = collect_metrics(split=split)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, valid_dataloader, optimizer) -> None:\n",
    "    pbar = tqdm(total=args.iters, desc='Train')\n",
    "    # pbar.update(n_iter)\n",
    "\n",
    "    train_batches = _train_batch_generator(train_dataloader, 0, args)\n",
    "    train_size = len(train_dataloader)\n",
    "\n",
    "    metric_improved_fn = lambda old_m, new_m: old_m < new_m\n",
    "\n",
    "    best_valid_metric = np.inf if args.optimize_mode == 'min' else -np.inf\n",
    "    valid_metric = best_valid_metric\n",
    "    valid_loss = np.inf\n",
    "    train_loss = np.inf\n",
    "    early_stopping_counter = 0\n",
    "    best_metric_trigger = False\n",
    "\n",
    "    for n_iter, batch in enumerate(train_batches):\n",
    "        iteration_start = time.time()\n",
    "        batch_metrics, batch_metrics_data = step(model, batch, optimizer, args, is_train_mode=True)\n",
    "        iteration_time = time.time() - iteration_start\n",
    "        _add_batch_metrics(batch_metrics, split='train')\n",
    "        if keep_for_metrics_fn and metrics_fn:\n",
    "            _add_metrics_data(batch_metrics_data, split='train')\n",
    "\n",
    "        # logging\n",
    "        # if args.log_interval and n_iter % args.log_interval == 0:\n",
    "            # batch-lvl averaged metrics:\n",
    "            # train_metrics = collect_metrics(split='train')\n",
    "            # train_loss = train_metrics['loss']\n",
    "\n",
    "        # validation\n",
    "        # if valid_dataloader is not None and n_iter % args.valid_interval == 0:\n",
    "        #     # todo: we can use other metrics than loss here\n",
    "        #     valid_metrics = validate(valid_dataloader)\n",
    "        #     valid_loss = valid_metrics['loss']\n",
    "        #     valid_metric = valid_metrics[args.optimize_metric]\n",
    "        #     if metric_improved_fn(best_valid_metric, valid_metric):\n",
    "        #         best_valid_metric = valid_metric\n",
    "        #         early_stopping_counter = 0\n",
    "        #         logger.info(f'The best {args.optimize_metric} metric was improved to: {best_valid_metric}')\n",
    "        #         if args.save_best:\n",
    "        #             torch.save(model, f\"{args.model_path}.pth\")\n",
    "        #     else:\n",
    "        #         early_stopping_counter += 1\n",
    "        #         logger.info(f'Metric was not improved for the last #{early_stopping_counter} evaluations')\n",
    "        #     if best_valid_metric == args.best_metric_value:\n",
    "        #         best_metric_trigger = True\n",
    "        \n",
    "        # pbar.update(1)\n",
    "        # pbar.set_postfix({'train_loss': f'{train_loss:.3f}',\n",
    "        #                     'valid_loss': f'{valid_loss:.3f}',\n",
    "        #                     f'best_valid_{args.optimize_metric}': f'{best_valid_metric:.3f}'\n",
    "        #                     })\n",
    "\n",
    "        # if args.early_stopping_patience is not None and \\\n",
    "        #         early_stopping_counter > args.early_stopping_patience or best_metric_trigger:\n",
    "        #     logger.info('Early stopping triggered: stopping training...')\n",
    "        #     break\n",
    "\n",
    "    # clean-up\n",
    "    pbar.close()\n",
    "    logger.info('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ca586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0eff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'batch_metrics' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dataloader, valid_dataloader, optimizer)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# logging\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.log_interval \u001b[38;5;129;01mand\u001b[39;00m n_iter % args.log_interval == \u001b[32m0\u001b[39m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# batch-lvl averaged metrics:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     train_metrics = \u001b[43mcollect_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     train_loss = train_metrics[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcollect_metrics\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m      7\u001b[39m     batch_metrics = defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mbatch_metrics\u001b[49m[split] = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     11\u001b[39m     metrics_data = defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'batch_metrics' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "train(model, pretrain_dataloader, valid_dataloader, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metamem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
